Title: BOLD: Bayesian Online Liar Detector via Ethereum Smart Contract Mechanism

CHECKLIST!!

[1] supervise learning - non- deep learning
- Understand the LIAR dataset
- read the Wang paper- liar liar pants on fire
- fix the jenky sklearn code
- get the appropriate results for acc, f1-score, prediction etc
- receive better results, eg: graphs, distribution, convolution matrix

[2] web framework
- create a flask based site
- setup SQL
- get/post command
- get good results (showing that the algorithm is learning etc)

[3] BERT ALGORITHM
- create BERT (bayesian deep NN) alg (pseudocode)??
- implement the BERT alg
- get highest qulaity acc on LIAR dataset ---- this is the most important result!!!
- define the alg and the architecture
- math model be defined

[4] BOLD archtiecture
- create a novel arch. that comprises ethereum smart contract
with BDNN alg
- sample implementation result
- BOLD arch. diagram is required
- future work in the area

---------------------THE END-------------------------------
Hello. these are the guiding notes in order to complete the thesis work. 
##please be informed that you require to complete the thesis case and extend I-20 to summer semester. these are hard times. I have seen harder times. rest asure, that we will make it through. <finger cross>
CS7999: program of completion:
Contents:
 - related work - dataset - architecture - results - conclusion
 
 #################################################################
 # The main contribution of the theis is to create a project called 
 # Go- news, which provides a solution for the fake news problem as
 # a symbiotic relationship of ML and blockchain/ smart contract.
 # it wont be easy but this thesis can be treated a final term project
 # porposal rather then a true reaserch endeavour.
 #################################################################
 ####################################################################
 BERT: Bidirectional Encoder Representation Transformer
 
 <def>: BERT is a deep neural network that uses pre-train bidrectional representation from unlabel text to perform language 
 related task, such as: Q&A, language inference, etc. It is fine-tuned ( ).
 
 : Bidirectional:
 :Encoder:
 :Transformer: 
 
 
